{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid vs. Non-Covid CT scan classification\n",
    "\n",
    "### ICCV 2021 Workshop: MIA-COV19D Competition\n",
    "### Test Data set analysis\n",
    "\n",
    "\n",
    "#### Author: Mohammad Nayeem Teli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os,csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model,models\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data directories and listing some files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'ICCV2021Data/COV19DCompetition/Data/test_subsets/'\n",
    "# test_dir = os.path.join(base_dir,'subset1/')\n",
    "# test_dir = os.path.join(base_dir,'subset2/')\n",
    "# test_dir = os.path.join(base_dir,'subset3/')\n",
    "# test_dir = os.path.join(base_dir,'subset4/')\n",
    "# test_dir = os.path.join(base_dir,'subset5/')\n",
    "# test_dir = os.path.join(base_dir,'subset6/')\n",
    "# test_dir = os.path.join(base_dir,'subset7/')\n",
    "# test_dir = os.path.join(base_dir,'subset8/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of test files in different sub folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFiles = 0\n",
    "totalDir = 0\n",
    "\n",
    "for base, dirs, files in os.walk(test_dir):\n",
    "#     print('Searching in : ',base)\n",
    "    for directories in dirs:\n",
    "        totalDir += 1\n",
    "    for Files in files:\n",
    "        _,ending = os.path.splitext(Files)\n",
    "        if ending == \".jpg\":\n",
    "            totalFiles += 1\n",
    "\n",
    "\n",
    "print('Total number of files',totalFiles)\n",
    "print('Total Number of directories',totalDir)\n",
    "print('Total:',(totalDir + totalFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_names(folder):\n",
    "    fs = []\n",
    "    for subdir, dirs, files in os.walk(folder, topdown=True):\n",
    "        for f in files:\n",
    "            _,ending = os.path.splitext(f)\n",
    "            if ending == \".jpg\":\n",
    "                fs.append(os.path.join(subdir,f))\n",
    "    return(fs)\n",
    "\n",
    "test_image_list = get_image_names(test_dir)\n",
    "                \n",
    "assert(totalFiles==len(test_image_list))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 8,488,481\n",
      "Trainable params: 8,487,521\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size =(256,256),\n",
    "            batch_size=32,\n",
    "            class_mode='binary',\n",
    "            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = model.predict(test_generator,steps= len(test_generator),workers=8,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels\n",
    "cls = np.round(preds)\n",
    "file_names = test_generator.filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the class labels corresponding to covid and non-covid class labels (covid : 0, non-covid: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results in a Data Frame that can be saved in .csv file\n",
    "results=pd.DataFrame({\"file\":file_names,\"pr\":preds[:,0], \"class\":cls[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the predicted labels for each subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_csv('subset1.csv', index=False)\n",
    "# results.to_csv('subset2.csv', index=False)\n",
    "# results.to_csv('subset3.csv', index=False)\n",
    "# results.to_csv('subset4.csv', index=False)\n",
    "# results.to_csv('subset5.csv', index=False)\n",
    "# results.to_csv('subset6.csv', index=False)\n",
    "# results.to_csv('subset7.csv', index=False)\n",
    "# results.to_csv('subset8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a copy of the dataframe to modify it. Separating the folder and the image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['folder','filename']] = df.file.str.split(\"/\",expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the folder name and the prediction of the dataframe into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.set_index('folder').to_dict()['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the folders as covid or non-covid in the respective files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('covid.csv','a') as f:\n",
    "    for key in d.keys():\n",
    "        if d[key]==0.0:\n",
    "            f.write(\"%s,\"% key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('non-covid.csv','a') as f:\n",
    "    for key in d.keys():\n",
    "        if d[key]==1.0:\n",
    "            f.write(\"%s,\"% key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
